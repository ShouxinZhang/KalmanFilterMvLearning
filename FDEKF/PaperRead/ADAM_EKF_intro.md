# 摘要 (Abstract)

本文阐明了扩展卡尔曼滤波器（EKF）在非线性系统辨识中作为学习率的物理含义。为了处理数据快速到达的应用场景，我们将完全解耦扩展卡尔曼滤波器（FDEKF）改进为一种新算法，称为循环完全解耦扩展卡尔曼滤波器（RR-FDEKF）。该算法在参数更新中引入了循环（Round-Robin）机制，利用一种专门构造的混合信息状态向量来立即使用新的测量信息。FDEKF 和 RR-FDEKF 的有效性在无源互调（PIM）抵消这一无线通信中的挑战性现实任务中得到了验证。实验结果表明，与深度学习中广受认可的 Adam 优化器相比，它们实现了更优的 PIM 抑制效果，并具有显著的计算优势。这些发现凸显了 FDEKF 和 RR-FDEKF 作为高效且高性能的在线非线性参数估计解决方案的潜力。

# I. 引言 (Introduction)

系统辨识是构建动态系统数学模型，并随后从观测数据中估计模型参数的过程。它是众多科学和工程领域（包括控制系统、信号处理、计量经济学和机器学习）中的基础性挑战 [1], [2]。虽然模型的架构确立了可实现的模型性能上限，但参数估计决定了性能的下限，即已辨识模型的实际保真度。

无线通信中无源互调（PIM）失真的缓解是需要高级系统辨识的一个突出例子。由于无源元件中的非线性，PIM 会产生不需要的干扰信号，严重降低接收机灵敏度，特别是在共址发射/接收系统或多载波场景中 [3], [4]。数字 PIM 抵消技术提供了一种灵活的解决方案，但其关键在于从观测信号中准确辨识潜在的非线性动态。捕捉 PIM 固有的复杂行为和记忆效应通常需要复杂的、高维非线性模型，例如 Volterra 级数或基函数网络 [5], [6]。高效且准确地估计这些模型中的大量参数是一项重大挑战，通过寻找合适的估计框架来解决这一问题显得尤为重要。

卡尔曼滤波框架是状态和参数估计的基石，为受高斯噪声影响的线性系统提供了均方误差意义下的最优估计器 [7]–[9]。此外，由于许多现实世界的系统表现出非线性动态或测量关系，扩展卡尔曼滤波器（EKF）被引入 [10]–[12]。EKF 通过在每个时间步围绕当前状态估计对系统进行线性化来处理非线性，从而能够应用卡尔曼滤波器中的预测-更新机制。其有效性已在从导航 [13] 到生物系统 [10], [14]–[21] 的各种应用中得到证明。

尽管 EKF 应用广泛，但在实际应用中仍面临重大障碍，特别是对于高维系统。当应用于系统辨识时，参数的数量（在下文中用 $n$ 表示）增加了系统的维度。由于 $n$ 可能非常大，辨识任务面临相当大的计算复杂性，通常由于涉及 $n \times n$ 协方差矩阵的运算，复杂度呈 $n$ 的二次方或更糟糕的比例增长。此外，它还会遇到潜在的数值不稳定性问题，特别是在高度非线性或初始化不佳的情况下 [22]。这些限制促使人们开发更高效、更稳健的 EKF 系统辨识应用方案。

## A. 动机 (Motivations)

为了克服 EKF 的计算和数值挑战，人们提出了各种近似和简化策略。一个主要的方向涉及解耦，旨在通过简化误差协方差矩阵的结构来降低复杂性，通常通过假设不同状态或参数之间均独立或相关性有限来实现。

在神经网络训练背景下，解耦的最初动力导致了独立 EKF（IEKF）理念的产生。Kollias 和 Anastassiou [23] 以及 Shah 和 Palmieri 的 MEKA 算法 [24] 等开创性工作建议为每个神经元的权重分配独立的滤波器。这些方法优先考虑完全的计算局部性，在局部执行更新并消除对全局协调矩阵的需求，从而实现显著的加速。在这些早期探索的基础上，Puskorius 和 Feldkamp [25] 引入了一种不同的公式，他们称之为解耦 EKF（DEKF）。虽然承认 IEKF 的效率，但他们的方法旨在通过保留一定程度的间接全局耦合来获得更严谨的理论依据。他们的框架即使在完全解耦的极限情况下，也通过包含所有参数信息的共享全局缩放矩阵来协调更新。其目的是产生比纯局部 IEKF 方法更稳定、更准确的性能。

本文重新审视并形式化了原始的 IEKF 哲学，专注于其最细粒度和计算效率最高的实现。我们采用一种公式，其中每个单独的参数都由一个独立的标量 EKF 更新。此后，我们将这种特定的、完全局部的变体称为完全解耦扩展卡尔曼滤波器（FDEKF），同时承认它与 Puskorius 和 Feldkamp 的全局协调版本在概念上的区别。这种独立估计的原理也在其他背景下得到了探索 [26], [27]。解耦策略本身也重新引起了人们的兴趣，类似 FDEKF 的方法已成功应用于深度神经网络训练等现代计算密集型领域 [21]。这一历史轨迹凸显了一个反复出现的主题：为解决过去的计算限制而开发的算法近似，随着问题规模的增长和计算能力的演变，往往会发现新的相关性。

这些解耦策略的实际成功促使我们需要从状态空间的角度进行清晰、形式化的推导。虽然早期作品中存在基础性见解 [23], [24]，但我们的工作为 FDEKF 提供了一个独立且直接的推导。这为系统分析提供了坚实的基础，并且作为直接扩展，允许我们引入一种称为循环完全解耦扩展卡尔曼滤波器（RR-FDEKF）的新变体。

## B. 贡献 (Contributions)

主要贡献总结如下：

1) **EKF 的可解释自适应学习率机制**：这项 work 提出了一个新的框架来解释 EKF 的更新机制，将卡尔曼增益视为一种可解释的、自适应的学习率。我们阐明了过程噪声 ($Q_k$)、测量噪声 ($R_k$) 和估计参数不确定性 ($P_k$) 之间的相互作用如何动态调整滤波器的学习率。这与 Adam 等现代优化器形成了鲜明对比，后者的自适应机制主要是启发式的，缺乏这种直接的物理基础。
2) **FDEKF 的形式化和 RR-FDEKF 的提出**：我们首先通过从状态空间模型推导 FDEKF，为其建立了严格的理论基础，阐明了其基本假设。在这个清晰的基础上，我们随后引入了 RR-FDEKF，这是一种改进了解耦扩展卡尔曼滤波器方法的新算法。RR-FDEKF 通过以顺序、循环的方式每次仅更新一个参数，专门设计用于数据到达率相对于可用计算资源较高的情况，特别是在处理大量参数时。
3) **通过高效系统辨识实现高性能数字 PIM 抵消**：我们通过开发一种基于解耦卡尔曼滤波的高效辨识方案，成功解决了数字 PIM 抵消这一具有挑战性的任务。使用真实世界数据的实验结果表明，与广泛使用的 Adam 优化器相比，我们的方法产生了更优的 PIM 抑制效果和更快的收敛速度，突显了其在复杂、现实世界通信系统中的实际功效。

## C. 组织结构 (Organization)

本文的其余部分组织如下。第二部分建立了我们工作的理论基础。它首先阐述了参数估计问题，然后从 EKF 的角度重新审视该问题，最终得出我们将滤波器的核心协方差矩阵解释为其自适应学习率背后的机制。在此基础上，第三部分介绍了两种计算高效的算法。我们首先基于状态空间模型推导 FDEKF，然后提出我们为高效在线应用设计的 RR-FDEKF。第四部分提供了所提出方法的全面实验验证。我们详细介绍了实验设置，定义了性能指标，并对结果进行了对比分析。最后，第五部分通过总结我们的主要发现并提出未来研究的潜在途径来结束本文。

## D. 符号说明 (Notations)

整篇论文中，我们遵循以下符号约定：

* 矩阵由粗体大写字母表示（例如，$\mathbf{P}, \mathbf{Q}, \mathbf{R}$）。卡尔曼增益 $\mathbf{K}_k$ 也以这种方式表示，因为它在一般情况下是一个矩阵。
* 向量是粗体小写字母表示的列向量（例如，$\boldsymbol{\theta}, \mathbf{x}, \mathbf{y}$）。如果未被其他约定覆盖，行向量也可以遵循此格式或表示为转置（例如，$\mathbf{h}^T$）。
* 标量由普通（非粗体）小写字母表示（例如，$n, p, q, t, k$）。
* 矩阵或向量的转置由上标 $T$ 表示（例如，$\mathbf{P}^T, \boldsymbol{\theta}^T$）。
* 右下标表示离散时间步（例如，$\boldsymbol{\theta}_k, \mathbf{y}_k$）。
* 估计值用帽子符号 ($\hat{\cdot}$) 表示。符号 $\hat{\boldsymbol{\theta}}_{k|j}$ 表示在给定直到时间 $j$ 的测量值的情况下，时间 $k$ 的 $\boldsymbol{\theta}$ 的估计值。为了简洁起见，更新后的估计 $\hat{\boldsymbol{\theta}}_{k|k}$ 及其协方差 $\mathbf{P}_{k|k}$ 通常简单地写为 $\hat{\boldsymbol{\theta}}_k$ 和 $\mathbf{P}_k$。
* 对于解耦算法，$P_k^i$ 表示第 $i$ 个参数的标量方差。
* 新息或测量残差表示为 $\tilde{\mathbf{y}}_k$。对于 RR-FDEKF 变体，它使用周期 $k$ 和周期内步骤 $i$ 的双重索引，写作 $\tilde{\mathbf{y}}_{k,i}$。

# 个人阅读 (Personal Reading)

## 背景算法 (Baseline Algorithms)

### 1. 传统梯度下降与 LMS

在非线性系统辨识中，除了使用解析解（仅适用于线性系统的 RLS），常用的替代方法是基于梯度的算法，如最小均方（LMS）算法或 Adam 优化器。LMS 依赖于固定的学习率 $\mu$，其更新公式为：

$$
\hat{\boldsymbol{\theta}}_k = \hat{\boldsymbol{\theta}}_{k-1} + \mu \mathbf{H}_k^T (\mathbf{y}_k - f(\hat{\boldsymbol{\theta}}_{k-1}; \mathbf{x}_k, \dots))
$$

虽然计算简单，但固定学习率在面对非平稳信号或复杂环境时难以平衡收敛速度和稳定性。Adam 优化器则是深度学习中广泛使用的基准，具有启发式的自适应学习率机制。

### 2. 标准扩展卡尔曼滤波 (Standard EKF)

EKF 将参数估计重新构建为状态空间模型中的概率推断问题。它通过协方差矩阵动态调整增益（即学习率）。

* **预测步骤**:

  $$
  \hat{\boldsymbol{\theta}}_{k|k-1} = \hat{\boldsymbol{\theta}}_{k-1}
  $$

  $$
  \mathbf{P}_{k|k-1} = \mathbf{P}_{k-1} + \mathbf{Q}_{k-1}
  $$
* **更新步骤**:

  $$
  \mathbf{K}_k = \mathbf{P}_{k|k-1} \mathbf{H}_k^T (\mathbf{H}_k \mathbf{P}_{k|k-1} \mathbf{H}_k^T + \mathbf{R}_k)^{-1}
  $$

  $$
  \hat{\boldsymbol{\theta}}_k = \hat{\boldsymbol{\theta}}_{k|k-1} + \mathbf{K}_k (\mathbf{y}_k - f(\hat{\boldsymbol{\theta}}_{k|k-1}; \dots))
  $$

  $$
  \mathbf{P}_k = (\mathbf{I} - \mathbf{K}_k \mathbf{H}_k) \mathbf{P}_{k|k-1}
  $$

**局限性**: EKF 实际上被限制于高维系统，因为其计算复杂度和存储需求随参数数量 $n$ 呈 $O(n^2)$ 增长（由于全协方差矩阵 $\mathbf{P}_k$ 的操作）。

## 改进算法 (Improved Algorithms)

为了解决 EKF 的计算瓶颈，本文在完全解耦 EKF (FDEKF) 的基础上提出了 循环完全解耦 EKF (RR-FDEKF)。

### 1. 完全解耦 EKF (FDEKF)

FDEKF 采用完全局部的实现，将每个参数 $\theta^i$ 视为独立的状态。虽然它避免了全局协方差矩阵的计算（复杂度降至 $O(nq^3)$，当输出维数 $q$ 小时约为 $O(n)$），但它仍然在每个时间步 $k$ 使用测量值 $\mathbf{y}_k$ 更新所有 $n$ 个参数。
在数据到达频率极高的场景下，更新所有 $n$ 个参数的处理时间可能超过测量间隔。

### 2. 循环完全解耦 EKF (RR-FDEKF)

为了进一步降低计算负担并适应高速数据流，RR-FDEKF 引入了循环（Round-Robin）更新机制。

* **核心思想**: 每一个测量数据 $\mathbf{y}_{k,i}$ 仅用于更新**一个**参数 $\theta^i$。
* **公式**: 使用“混合周期”信息向量 $\boldsymbol{\xi}^i_k$ 来利用最新的估计值：

  $$
  \boldsymbol{\xi}^i_k = [\hat{\theta}^1_k, \dots, \hat{\theta}^{i-1}_k, \hat{\theta}^{i+1}_{k-1}, \dots, \hat{\theta}^n_{k-1}]^T
  $$

  更新过程（针对第 $i$ 个参数）：
  $$
  \hat{\theta}^i_k = \hat{\theta}^i_{k|k-1} + K_{k,i} (y_{k,i} - f_i(\hat{\theta}^i_{k|k-1}; \boldsymbol{\xi}^i_k, \dots))
  $$
* **优势**: 计算复杂度进一步降低，每个物理时间步仅需 $O(1)$ 的操作（针对单参数更新）。并且通过立即利用同一周期内先前更新的参数信息，加速了收敛。

## EKF → FDEKF → RR-FDEKF：算法演进总结（按“为什么/改了啥/带来啥”）

这条演进线的目标很单一：**保留 EKF 的不确定性驱动更新（Kalman 增益可解释为自适应学习率），同时把高维参数估计的计算代价降下来，直到能跟上高数据率的在线场景。**

### 1) EKF：完整不确定性融合（强，但贵）

- **建模（参数当状态）**：

  $$
  \hat{\theta}_k = \hat{\theta}_{k-1} + w_{k-1},\quad y_k = f(\hat{\theta}_k; x_k,\dots) + v_k
  $$
- **Kernel（自适应学习率矩阵）**：

  $$
  k = P_{k|k-1} H_k^T \big(H_k P_{k|k-1} H_k^T + R_k\big)^{-1}
  $$

  其中 $K_k$ 根据 $P,Q,R$ 自动调节“信任新数据/信任旧估计”的权重。
- **为什么需要演进**：维护并更新完整协方差 $P_k\in\mathbb{R}^{n\times n}$，高维时计算与存储开销近似 $O(n^2)$，在线大模型辨识往往不可承受。

### 2) FDEKF：把“全协方差”砍成“对角协方差”（从 $O(n^2)$ 到近似 $O(n)$）

- **关键改动**：忽略参数间相关性（等价于 $P_k$ 仅保留对角项）。
- **等价实现**：把 $n$ 维 EKF 拆成 $n$ 个标量 EKF，每个参数 $\theta^i$ 自己维护一个标量方差 $P_k^i$。
- **带来的效果**：当测量维数 $q$ 很小（论文 PIM 实验 $q=1$）时，整体复杂度接近线性 $O(n)$。
- **仍然卡住的点**：每来一个样本 $y_k$，仍需要把 $i=1\dots n$ 的参数全更新一遍；在高数据率流式场景里，可能“样本到得比计算快”。

### 3) RR-FDEKF：把“每步全更”改成“每步轮询更一个”（让吞吐跟上数据率）

- **Kernel 改动**：每个物理时间步只更新一个参数，参数索引按 Round-Robin 轮换。
- **为什么不会信息完全断流**：更新第 $i$ 个参数时，构造混合向量
  $$
  i_k^i = [\hat\theta_k^1,\dots,\hat\theta_k^{i-1},\hat\theta_{k-1}^{i+1},\dots,\hat\theta_{k-1}^n]^T
  $$

  让同一“周期”里刚更新过的参数立即参与后续更新，形成信息级联，降低“只更新一个参数”带来的滞后。
- **带来的效果**：单步开销近似 $O(1)$（一条数据只更一个参数）；每 $n$ 个样本完成一轮全参数更新，特别适合低时延/流水线实现。

### 一句话 Kernel 总结

- **EKF**：最完整，但全协方差 $P$ 太贵。
- **FDEKF**：把 $P$ 对角化 → $n$ 个标量 EKF，复杂度近似线性。
- **RR-FDEKF**：在 FDEKF 上再把“每样本更新全部参数”改为“每样本轮询更新一个参数 + 混合向量级联”，适配高速在线数据流。

# Fig 4 参数配置

图 4 展示了参考 PIM 信号的功率谱密度（PSD）以及经 FDEKF、RR-FDEKF 和 Adam 抵消后的残差信号。该实验采用了以下关键参数配置（基于 "B. Evaluation Setup" 章节）：

## 1. 实验环境与通用设置
*   **硬件**: Intel(R) Xeon(R) CPU @ 2.20GHz
*   **软件框架**: PyTorch (Python)
*   **数据集**: 64,800 个样本 (1 epoch)
*   **统计验证**: 20 次随机种子重复实验
*   **参数初始化**: $N(0, 0.01)$

## 2. 算法超参数配置

### Adam (Baseline)
*   **学习率 ($\alpha$)**: $0.001$
*   **指数衰减率**: $\beta_1 = 0.9$, $\beta_2 = 0.999$
*   **$\epsilon$**: $10^{-8}$

### FDEKF & RR-FDEKF
两者配置相同以确保公平对比：
*   **初始参数误差方差 ($P_0^i$)**: $0.01$ (与参数初始化方差一致)
*   **测量噪声方差 ($R_k$)**: $10^{-8}$ (基于接收通道固有噪声计算)
*   **过程噪声方差 ($Q_k^i$) 动态调度**:
    1.  **预热期 (前 10 epochs)**: $Q_k^i = 0$ (加速收敛)
    2.  **激活期**: 增加至 $10^{-6}$ (防止卡尔曼增益消失)
    3.  **衰减期**: 每 50 epochs 衰减 0.7 倍
    4.  **下限**: 最小值为 $10^{-12}$
